// tests/e2e/deployment/pre-deploy-check.js
import { AITestRunner } from '../runner/test-runner.js';
import { createClient } from '@supabase/supabase-js';
import Anthropic from '@anthropic-ai/sdk';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_KEY
);

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY
});

export class PreDeploymentChecker {
  constructor() {
    this.criticalPaths = [
      { name: 'Authentication Flow', path: '/login', required: true },
      { name: 'Dashboard Access', path: '/dashboard', required: true },
      { name: 'Core User Journey', path: '/app', required: true },
      // Add your critical paths here
    ];
    this.performanceThresholds = {
      pageLoad: 3000, // 3 seconds
      apiResponse: 1000, // 1 second
      totalTestTime: 300000 // 5 minutes
    };
  }

  async runPreDeploymentChecks() {
    console.log('ðŸš€ Starting Pre-Deployment E2E Checks...\n');

    const startTime = Date.now();
    const results = {
      timestamp: new Date().toISOString(),
      environment: process.env.NODE_ENV || 'development',
      commitHash: process.env.GITHUB_SHA || 'local',
      branch: process.env.GITHUB_REF || 'local',
      checks: [],
      aiRiskAssessment: null,
      deploymentRecommendation: null
    };

    try {
      // 1. Run critical path tests
      console.log('1ï¸âƒ£ Testing Critical User Paths...');
      const criticalPathResults = await this.testCriticalPaths();
      results.checks.push(criticalPathResults);

      // 2. Performance regression check
      console.log('\n2ï¸âƒ£ Checking for Performance Regressions...');
      const performanceResults = await this.checkPerformanceRegression();
      results.checks.push(performanceResults);

      // 3. Accessibility compliance
      console.log('\n3ï¸âƒ£ Verifying Accessibility Compliance...');
      const accessibilityResults = await this.checkAccessibility();
      results.checks.push(accessibilityResults);

      // 4. Security headers check
      console.log('\n4ï¸âƒ£ Validating Security Headers...');
      const securityResults = await this.checkSecurityHeaders();
      results.checks.push(securityResults);

      // 5. API contract testing
      console.log('\n5ï¸âƒ£ Testing API Contracts...');
      const apiResults = await this.testAPIContracts();
      results.checks.push(apiResults);

      // 6. Database migration verification
      console.log('\n6ï¸âƒ£ Verifying Database Migrations...');
      const dbResults = await this.verifyDatabaseState();
      results.checks.push(dbResults);

      // Get AI risk assessment
      results.aiRiskAssessment = await this.getAIRiskAssessment(results);

      // Generate deployment recommendation
      results.deploymentRecommendation = await this.generateDeploymentRecommendation(results);

      // Save results
      await this.saveResults(results);

      // Print summary
      this.printSummary(results);

      // Exit with appropriate code
      const shouldDeploy = results.deploymentRecommendation.shouldDeploy;
      process.exit(shouldDeploy ? 0 : 1);

    } catch (error) {
      console.error('âŒ Pre-deployment check failed:', error);
      results.error = error.message;
      await this.saveResults(results);
      process.exit(1);
    }
  }

  async testCriticalPaths() {
    const results = {
      name: 'Critical Path Testing',
      status: 'pending',
      details: []
    };

    for (const path of this.criticalPaths) {
      console.log(`  Testing ${path.name}...`);

      try {
        const testResult = await this.runPathTest(path);
        results.details.push({
          path: path.name,
          success: testResult.success,
          duration: testResult.duration,
          errors: testResult.errors
        });

        if (!testResult.success && path.required) {
          results.status = 'failed';
        }
      } catch (error) {
        results.details.push({
          path: path.name,
          success: false,
          error: error.message
        });
        if (path.required) {
          results.status = 'failed';
        }
      }
    }

    if (results.status !== 'failed') {
      results.status = 'passed';
    }

    return results;
  }

  async runPathTest(path) {
    // This would run actual Puppeteer tests for the path
    // Simplified for example
    const startTime = Date.now();

    try {
      // Run the specific test for this path
      const runner = new AITestRunner();
      await runner.runTests();

      return {
        success: runner.results.success,
        duration: Date.now() - startTime,
        errors: runner.results.errorOutput
      };
    } catch (error) {
      return {
        success: false,
        duration: Date.now() - startTime,
        errors: error.message
      };
    }
  }

  async checkPerformanceRegression() {
    // Get baseline metrics from last successful deployment
    const { data: baseline } = await supabase
      .from('deployment_baselines')
      .select('*')
      .eq('status', 'success')
      .order('created_at', { ascending: false })
      .limit(1)
      .single();

    if (!baseline) {
      return {
        name: 'Performance Regression Check',
        status: 'warning',
        message: 'No baseline found, skipping regression check'
      };
    }

    // Compare current metrics with baseline
    const currentMetrics = await this.collectPerformanceMetrics();
    const regressions = [];

    for (const [key, value] of Object.entries(currentMetrics)) {
      const baselineValue = baseline.metrics[key];
      if (baselineValue && value > baselineValue * 1.2) { // 20% regression threshold
        regressions.push({
          metric: key,
          baseline: baselineValue,
          current: value,
          regression: ((value - baselineValue) / baselineValue * 100).toFixed(2) + '%'
        });
      }
    }

    return {
      name: 'Performance Regression Check',
      status: regressions.length > 0 ? 'failed' : 'passed',
      regressions,
      currentMetrics
    };
  }

  async collectPerformanceMetrics() {
    // This would collect real metrics
    // Simplified for example
    return {
      homePageLoad: 1245,
      loginPageLoad: 892,
      dashboardPageLoad: 1567,
      apiAuthResponse: 234,
      apiDataFetch: 456
    };
  }

  async checkAccessibility() {
    // Run accessibility tests using axe-core or similar
    return {
      name: 'Accessibility Compliance',
      status: 'passed',
      violations: [],
      warnings: []
    };
  }

  async checkSecurityHeaders() {
    const requiredHeaders = [
      'Content-Security-Policy',
      'X-Frame-Options',
      'X-Content-Type-Options',
      'Strict-Transport-Security'
    ];

    const results = {
      name: 'Security Headers Check',
      status: 'pending',
      missingHeaders: [],
      presentHeaders: []
    };

    // Check headers on your deployment
    try {
      const response = await fetch(process.env.DEPLOY_URL || 'http://localhost:3000');
      const headers = response.headers;

      for (const header of requiredHeaders) {
        if (headers.get(header)) {
          results.presentHeaders.push(header);
        } else {
          results.missingHeaders.push(header);
        }
      }

      results.status = results.missingHeaders.length === 0 ? 'passed' : 'failed';
    } catch (error) {
      results.status = 'failed';
      results.error = error.message;
    }

    return results;
  }

  async testAPIContracts() {
    // Test critical API endpoints
    const endpoints = [
      { path: '/api/auth/session', method: 'GET' },
      { path: '/api/user/profile', method: 'GET' },
      // Add your critical endpoints
    ];

    const results = {
      name: 'API Contract Testing',
      status: 'passed',
      endpoints: []
    };

    for (const endpoint of endpoints) {
      try {
        const response = await fetch(`${process.env.DEPLOY_URL || 'http://localhost:3000'}${endpoint.path}`, {
          method: endpoint.method,
          headers: {
            'Content-Type': 'application/json',
            // Add auth headers if needed
          }
        });

        results.endpoints.push({
          path: endpoint.path,
          status: response.status,
          success: response.ok
        });

        if (!response.ok && endpoint.required) {
          results.status = 'failed';
        }
      } catch (error) {
        results.endpoints.push({
          path: endpoint.path,
          success: false,
          error: error.message
        });
        results.status = 'failed';
      }
    }

    return results;
  }

  async verifyDatabaseState() {
    try {
      // Check if migrations are up to date
      const { data: migrations } = await supabase
        .from('schema_migrations')
        .select('*')
        .order('version', { ascending: false })
        .limit(1);

      // Verify critical tables exist
      const criticalTables = ['users', 'e2e_test_results', 'deployment_baselines'];
      const tableChecks = [];

      for (const table of criticalTables) {
        const { error } = await supabase.from(table).select('count').limit(1);
        tableChecks.push({
          table,
          exists: !error
        });
      }

      return {
        name: 'Database State Verification',
        status: tableChecks.every(t => t.exists) ? 'passed' : 'failed',
        latestMigration: migrations?.[0]?.version,
        tableChecks
      };
    } catch (error) {
      return {
        name: 'Database State Verification',
        status: 'failed',
        error: error.message
      };
    }
  }

  async getAIRiskAssessment(results) {
    const prompt = `Analyze these pre-deployment test results and assess the risk:

    Results: ${JSON.stringify(results, null, 2)}

    Provide:
    1. Overall risk level (low/medium/high/critical)
    2. Key risk factors
    3. Potential user impact
    4. Mitigation recommendations`;

    const response = await anthropic.messagess.create({
      model: "claude-3-opus-20240229",
      messages: [
        {
          role: "system",
          content: "You are a deployment risk assessment expert. Analyze test results and provide clear, actionable risk assessments."
        },
        {
          role: "user",
          content: prompt
        }
      ]
    });

    return response.choices[0].message.content;
  }

  async generateDeploymentRecommendation(results) {
    const failedCriticalChecks = results.checks.filter(
      c => c.status === 'failed' && c.required
    ).length;

    const recommendation = {
      shouldDeploy: failedCriticalChecks === 0,
      confidence: 'high',
      reasons: [],
      conditions: []
    };

    if (failedCriticalChecks > 0) {
      recommendation.reasons.push(`${failedCriticalChecks} critical checks failed`);
      recommendation.confidence = 'high';
    }

    // Check for performance regressions
    const perfCheck = results.checks.find(c => c.name === 'Performance Regression Check');
    if (perfCheck?.regressions?.length > 0) {
      recommendation.shouldDeploy = false;
      recommendation.reasons.push('Significant performance regressions detected');
    }

    // Add conditions for conditional deployment
    if (recommendation.shouldDeploy) {
      recommendation.conditions.push('Monitor error rates closely for first hour');
      recommendation.conditions.push('Be ready to rollback if issues arise');
    }

    return recommendation;
  }

  async saveResults(results) {
    // Save to Supabase
    await supabase
      .from('deployment_checks')
      .insert([{
        ...results,
        created_at: new Date().toISOString()
      }]);

    // Save to file for CI/CD artifacts
    const fs = await import('fs/promises');
    await fs.writeFile(
      'deployment-check-results.json',
      JSON.stringify(results, null, 2)
    );
  }

  printSummary(results) {
    console.log('\n' + '='.repeat(80));
    console.log('ðŸ“‹ PRE-DEPLOYMENT CHECK SUMMARY');
    console.log('='.repeat(80));

    for (const check of results.checks) {
      const icon = check.status === 'passed' ? 'âœ…' : 
                   check.status === 'warning' ? 'âš ï¸' : 'âŒ';
      console.log(`${icon} ${check.name}: ${check.status.toUpperCase()}`);

      if (check.regressions?.length > 0) {
        console.log('   Performance Regressions:');
        check.regressions.forEach(r => {
          console.log(`   - ${r.metric}: ${r.regression} slower`);
        });
      }
    }

    console.log('\nðŸ¤– AI Risk Assessment:');
    console.log(results.aiRiskAssessment);

    console.log('\nðŸ“Š Deployment Recommendation:');
    console.log(`Should Deploy: ${results.deploymentRecommendation.shouldDeploy ? 'YES âœ…' : 'NO âŒ'}`);

    if (results.deploymentRecommendation.reasons.length > 0) {
      console.log('Reasons:');
      results.deploymentRecommendation.reasons.forEach(r => {
        console.log(`- ${r}`);
      });
    }

    if (results.deploymentRecommendation.conditions.length > 0) {
      console.log('Conditions:');
      results.deploymentRecommendation.conditions.forEach(c => {
        console.log(`- ${c}`);
      });
    }

    console.log('='.repeat(80));
  }
}

// Run if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  const checker = new PreDeploymentChecker();
  checker.runPreDeploymentChecks().catch(console.error);
}